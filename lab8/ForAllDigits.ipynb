{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf15e015-8e16-41db-b9c4-71ae7976f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed08e130-9fcc-470b-8412-f54c3878aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data.to_numpy(), mnist.target.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faebff4d-9840-4ad8-8f5a-78083e94c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6ad26b-62db-4f87-9b52-735f28089cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, epochs=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.epochs = epochs\n",
    "        self.w = None\n",
    "        self.b = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        for _ in range(self.epochs):\n",
    "            for i, x_i in enumerate(X):\n",
    "                condition = y[i] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)  \n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y[i]))\n",
    "                    self.b -= self.lr * y[i]\n",
    "\n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        return np.sign(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d747d9-e36f-44c1-bfa3-04196cf668a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = np.mean(X_c, axis=0)\n",
    "            self.var[c] = np.var(X_c, axis=0) + 1e-9\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = [self._predict_single(x) for x in X]\n",
    "        return np.array(preds)\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        posteriors = []\n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])\n",
    "            class_conditional = np.sum(np.log(self._pdf(c, x)))\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        var += 1e-9\n",
    "        return norm.pdf(x, mean, np.sqrt(var)) + 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4c020-9002-4345-b0f1-d4c5e9b2acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVM()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "nb_model = NaiveBayes()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605dba5-010c-4e05-9819-c6f20917e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average=None)\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average=None)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average=None)\n",
    "\n",
    "precision_nb = precision_score(y_test, y_pred_nb, average=None)\n",
    "recall_nb = recall_score(y_test, y_pred_nb, average=None)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average=None)\n",
    "\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516b2a7-bc11-42c7-905a-9d25ca91d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "print(f\"Naïve Bayes Accuracy: {accuracy_nb}\")\n",
    "print(\"Confusion Matrix for SVM:\\n\", conf_matrix_svm)\n",
    "print(\"Confusion Matrix for Naïve Bayes:\\n\", conf_matrix_nb)\n",
    "print(\"SVM Precision:\", precision_svm)\n",
    "print(\"SVM Recall:\", recall_svm)\n",
    "print(\"SVM F1-score:\", f1_svm)\n",
    "print(\"Naïve Bayes Precision:\", precision_nb)\n",
    "print(\"Naïve Bayes Recall:\", recall_nb)\n",
    "print(\"Naïve Bayes F1-score:\", f1_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
